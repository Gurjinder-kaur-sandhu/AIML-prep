{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7be44fc8",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">RANDOM FOREST</h1>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2a2c759",
   "metadata": {},
   "source": [
    "Many weak trees together make a strong model.\n",
    "\n",
    "Random Forest combines multiple decision trees to improve accuracy and reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d4220f",
   "metadata": {},
   "source": [
    "## Ensemble learning\n",
    "Combining predictions from multiple models to get better performance than a single model.\n",
    "\n",
    "### Types of Ensemble Learning:\n",
    "\n",
    "Bagging → Random Forest (✔️)\n",
    "\n",
    "Boosting → AdaBoost, XGBoost\n",
    "\n",
    "Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b23aec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "data = load_wine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be5d8e",
   "metadata": {},
   "source": [
    "### Create X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a4a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data        # Features\n",
    "y = data.target     # Labels (0, 1, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf12a03",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b48e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4521b8d",
   "metadata": {},
   "source": [
    "### import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8deddd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e4fb4",
   "metadata": {},
   "source": [
    "### Create Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870b6a3b",
   "metadata": {},
   "source": [
    "The parameter n_estimators=200 specifies the number of decision trees in the forest. In Random Forest, each tree is trained on a different bootstrap sample of the training data and uses a random subset of features at each split. By setting n_estimators to 200, the model will build 200 individual decision trees. Increasing the number of trees generally improves model performance and stability because the predictions are averaged (or voted) across more trees, which reduces variance and overfitting. However, more trees also increase computational cost and training time, so this value is a balance between accuracy and efficiency.\n",
    "\n",
    "The parameter random_state=42 sets the random seed used by the algorithm. Random Forest involves randomness in two main places: sampling data points (bootstrap sampling) and selecting random subsets of features at each split. By fixing the random_state, the randomness becomes reproducible, meaning that every time you run the code with the same data and parameters, you will get the same model and the same results. This is especially important for debugging, comparison of models, and reproducible experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f9ef076",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,    # number of trees\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a892f440",
   "metadata": {},
   "source": [
    "### fit() and predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "965d6fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2ded11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af9c6b4",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af746cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d712cd",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0977ba47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0]\n",
      " [ 0 18  0]\n",
      " [ 0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febf8e90",
   "metadata": {},
   "source": [
    "# FEATURE IMPORTANCE\n",
    "Which features are most important for prediction?\n",
    "\n",
    "### This improves:\n",
    "\n",
    "Interpretability\n",
    "\n",
    "Trust in model\n",
    "\n",
    "Feature selection\n",
    "\n",
    "\n",
    "\n",
    "Random Forest provides feature importance, helping in model interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7086a82d",
   "metadata": {},
   "source": [
    "This code is used to analyze and interpret a trained Random Forest model by identifying which input features are most important for making predictions. First, the pandas library is imported to allow creation and manipulation of structured tabular data. The line importances = model.feature_importances_ extracts the feature importance scores from the trained Random Forest model; these scores are numerical values that indicate how much each feature contributed to reducing impurity across all the decision trees in the forest, and together they sum to 1. Next, a pandas DataFrame is created using a dictionary where one column, Feature, contains the names of the input features obtained from data.feature_names, and the second column, Importance, contains the corresponding importance scores from the model. Each feature name aligns index-wise with its importance value. The DataFrame is then sorted in descending order using the sort_values method so that the most influential features appear at the top, making interpretation easier. Finally, print(importance_df) displays the sorted table, allowing us to clearly see which features have the greatest impact on the model’s predictions, thereby improving model interpretability and helping with feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0a58533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Feature  Importance\n",
      "6                     flavanoids    0.187065\n",
      "9                color_intensity    0.170184\n",
      "12                       proline    0.156942\n",
      "0                        alcohol    0.121404\n",
      "11  od280/od315_of_diluted_wines    0.117764\n",
      "10                           hue    0.058332\n",
      "5                  total_phenols    0.047604\n",
      "3              alcalinity_of_ash    0.034880\n",
      "4                      magnesium    0.030259\n",
      "8                proanthocyanins    0.028778\n",
      "1                     malic_acid    0.026466\n",
      "2                            ash    0.013385\n",
      "7           nonflavanoid_phenols    0.006937\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "importances = model.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': data.feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ff806",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
